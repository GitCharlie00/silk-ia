{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementazione di un classificatore con Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Importo le librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Sigmoid o Logistic function\n",
    "Per effettuare la classificazione serve una funzione con codominio [0,1]. Infatti la predizione si baserà sulla probabilità della stima di appartenere ad una o all'altra classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    den = 1 + np.exp(-z)\n",
    "    sigm = 1.0/den\n",
    "    return sigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Funzione di ipotesi\n",
    "Per approssimare una probabilità, la funzione di costo sarà basta sulla funzione logisitca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyp(W,X):\n",
    "    param = np.dot(W,X.T)\n",
    "    return logistic(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Funzione di costo\n",
    "Da massimizzare nello step di ottimizzazione. IN particolare il logaritmo della funzione di coston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(W,X,Y):\n",
    "    m = X.shape[0]\n",
    "    h = hyp(W,X)\n",
    "    log_h = np.log(h)\n",
    "    log_one_h = np.log(1-h)\n",
    "    l_cost = float((-1.0/m) * ((np.dot(log_h,Y)) + (np.dot(log_one_h,(1-Y)))))\n",
    "    return l_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Carico e preparo i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1175, 5)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carico il dataset\n",
    "path = '../color_extr/data.csv'\n",
    "data = pd.read_csv(path, usecols = [i for i in range(5)])\n",
    "\n",
    "# Creo train e test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data[['presenza_foglie','assenza_foglie','presenza_bachi_sfondo','assenza_bachi_sfondo']], data[['classificazione']], test_size=0.13)\n",
    "\n",
    "m_tr, n_tr = X_train.shape\n",
    "X_train = np.concatenate((np.ones((m_tr,1)), X_train), axis=1)\n",
    "n_tr +=1\n",
    "\n",
    "m_te, n_te = X_test.shape\n",
    "X_test = np.concatenate((np.ones((m_te,1)), X_test), axis=1)\n",
    "n_te += 1\n",
    "\n",
    "W = np.array(np.zeros((1,n_te)))\n",
    "#W = np.matrix(np.random.randn((n_te)))\n",
    "\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_test = Y_test.to_numpy()\n",
    "\n",
    "# Normalizzo i dati\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "#cost(W,X_train,Y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Fit dell'algoritmo con gradient ascent\n",
    "Cerco il punto di massimo della funzione di costo per trovare i pesi ottimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n",
      "9.996220303384873e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.52315735, -3.3956016 ,  0.519256  ,  5.24509767,  0.52074973]]), 1)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_ascent(X,W,Y,alpha,stop):\n",
    "    m,n = X.shape\n",
    "    cost_old = np.inf\n",
    "    cost_new = cost(W,X,Y)\n",
    "    print(cost_old - cost(W,X,Y))\n",
    "    sum = 0\n",
    "    iter = 0\n",
    "\n",
    "    while(abs(cost_old-cost_new) > stop):\n",
    "        for j in range(0,n):\n",
    "            for i in range(0,m):\n",
    "                sum += (Y[i][0] - hyp(W,X[i])) * X[i][j]\n",
    "            W[0][j] = W[0][j] + (alpha/m) * sum\n",
    "        cost_old = cost_new\n",
    "        cost_new = cost(W,X,Y)\n",
    "        print(cost_old - cost(W,X,Y))\n",
    "        iter += 1\n",
    "\n",
    "    return W, iter  \n",
    "\n",
    "gradient_ascent(X_train,W,Y_train,0.04,0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Model Assestement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9753191489361702, 0.9261363636363636)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prediction(W,X,Y):\n",
    "    m = X.shape[0]\n",
    "    Y_hat = hyp(X, W) > 0.5\n",
    "    accuracy = 1.0/m * np.sum(Y == Y_hat)\n",
    "    return accuracy, Y_hat\n",
    "\n",
    "prediction(W,X_train,Y_train)[0],prediction(W,X_test,Y_test)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "702afc27125c4b44e8d6e4d91e2be92deaff276ecbbea6cc8c365578c4a94287"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
